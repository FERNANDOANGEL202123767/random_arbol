from flask import Flask, jsonify, request, render_template
from flask_cors import CORS
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score, f1_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeClassifier, plot_tree
from pandas import DataFrame
import matplotlib.pyplot as plt
import io
import base64
import os
from matplotlib.colors import ListedColormap
import logging

# Configuración del logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):
    strat = df[stratify] if stratify else None
    train_set, test_set = train_test_split(
        df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)
    strat = test_set[stratify] if stratify else None
    val_set, test_set = train_test_split(
        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)
    return (train_set, val_set, test_set)

def remove_labels(df, label_name):
    X = df.drop(label_name, axis=1)
    y = df[label_name].copy()
    return (X, y)

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/action/<action>', methods=['GET'])
def action(action):
    try:
        # Leer el dataset localmente
        df = pd.read_csv('data/archivo_reducido.csv')
        
        if action == 'load_data':
            data_head = df.head(10).to_html()
            return jsonify({"message": "Datos cargados", "data": data_head})
        
        elif action == 'length_features':
            data_length = len(df)
            num_features = len(df.columns)
            return jsonify({"message": "Longitud y Características", "length": data_length, "features": num_features})
        
        elif action == 'split_scale':
            train_set, val_set, test_set = train_val_test_split(df, stratify='calss')
            X_train, y_train = remove_labels(train_set, 'calss')
            X_val, y_val = remove_labels(val_set, 'calss')
            X_test, y_test = remove_labels(test_set, 'calss')
            
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_train_scaled = DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
            data_scaled_head = X_train_scaled.head(10).to_html()
            
            return jsonify({"message": "Dataset dividido y escalado", "scaled_data": data_scaled_head})
        
        elif action == 'train_tree':
            train_set, val_set, test_set = train_val_test_split(df, stratify='calss')
            X_train, y_train = remove_labels(train_set, 'calss')
            X_val, y_val = remove_labels(val_set, 'calss')
            
            clf_tree = DecisionTreeClassifier(random_state=42)
            clf_tree.fit(X_train, y_train)
            
            y_train_pred = clf_tree.predict(X_train)
            f1_train = f1_score(y_train, y_train_pred, average="weighted")
            
            y_val_pred = clf_tree.predict(X_val)
            f1_val = f1_score(y_val, y_val_pred, average="weighted")
            
            return jsonify({"message": "Modelo entrenado", "f1_train": float(f1_train), "f1_val": float(f1_val)})
            
    except Exception as e:
        logger.error(f"Error en la acción {action}: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/train', methods=['POST'])
def train_model():
    try:
        # Leer el dataset localmente
        df = pd.read_csv('data/archivo_completo.csv')
        
        # Convertir la columna 'calss' a valores numéricos
        df['calss'], _ = pd.factorize(df['calss'])
        
        train_set, val_set, test_set = train_val_test_split(df, stratify='calss')
        X_train, y_train = remove_labels(train_set, 'calss')
        X_val, y_val = remove_labels(val_set, 'calss')
        X_test, y_test = remove_labels(test_set, 'calss')
        
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)
        X_test_scaled = scaler.transform(X_test)
        
        rf_model = RandomForestRegressor(
            n_estimators=5,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42
        )
        rf_model.fit(X_train, y_train)
        
        y_pred = rf_model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        importancia = pd.DataFrame({
            'caracteristica': X_train.columns,
            'importancia': rf_model.feature_importances_
        }).sort_values('importancia', ascending=False)
        
        plt.switch_backend('Agg')
        plt.figure(figsize=(10, 6))
        plt.scatter(y_test, y_pred, alpha=0.5)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        plt.xlabel('Valores reales')
        plt.ylabel('Predicciones')
        plt.title('Predicciones vs Valores Reales')
        plt.tight_layout()
        
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
        img_buffer.seek(0)
        plt.close()
        
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
        
        response = {
            "mse": float(mse),
            "r2": float(r2),
            "feature_importance": importancia.to_dict(orient='records'),
            "image": img_base64
        }
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"Error en el entrenamiento del modelo: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/decision_boundary', methods=['GET'])
def decision_boundary():
    try:
        # Cargar el dataset reducido localmente
        data = pd.read_csv('data/archivo_reducido.csv')
        X_train = data[['min_flowpktl', 'flow_fin']]
        y_train = data['calss']

        # Codificar etiquetas
        label_encoder = LabelEncoder()
        y_train_encoded = label_encoder.fit_transform(y_train)

        # Reducir y escalar los datos
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)

        # Entrenar árbol de decisión
        clf_tree_reduced = DecisionTreeClassifier(random_state=42)
        clf_tree_reduced.fit(X_train_scaled, y_train_encoded)

        # Convertir los datos a numpy arrays
        X_train_np = X_train_scaled
        y_train_np = y_train_encoded

        # Verifica que los datos no contengan NaN o inf
        if np.any(np.isnan(X_train_np)) or np.any(np.isinf(X_train_np)):
            return jsonify({'error': 'Los datos contienen valores NaN o infinitos'}), 400

        # Crea la malla para graficar
        mins = X_train_np.min(axis=0) - 1
        maxs = X_train_np.max(axis=0) + 1
        x1, x2 = np.meshgrid(np.linspace(mins[0], maxs[0], 1000), np.linspace(mins[1], maxs[1], 1000))

        X_new = np.c_[x1.ravel(), x2.ravel()]
        y_pred = clf_tree_reduced.predict(X_new).reshape(x1.shape)

        # Graficar
        plt.figure(figsize=(12, 6))
        custom_cmap = ListedColormap(['#fafab0', '#9898ff', '#a0faa0'])
        plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)
        scatter = plt.scatter(X_train_np[:, 0], X_train_np[:, 1], 
                              c=y_train_np, edgecolors='k', cmap=custom_cmap, s=50, label='Entrenamiento')
        plt.xlim(mins[0], maxs[0])
        plt.ylim(mins[1], maxs[1])
        plt.xticks(np.arange(mins[0], maxs[0] + 1, 200))
        plt.yticks(np.arange(mins[1], maxs[1] + 1, 0.5))
        plt.xlabel('min_flowpktl', fontsize=14)
        plt.ylabel('flow_fin', fontsize=14, rotation=90)
        plt.title('Límite de Decisión', fontsize=16)
        plt.legend(*scatter.legend_elements(), title="Clases")
        
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
        img_buffer.seek(0)
        plt.close()
        
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
        
        return jsonify({'message': 'Límite de decisión graficado!', 'image': img_base64})

    except Exception as e:
        logger.error(f"Error en el límite de decisión: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/decision_tree', methods=['GET'])
def decision_tree():
    try:
        # Cargar el dataset reducido localmente
        data = pd.read_csv('data/archivo_reducido.csv')
        X_train = data[['min_flowpktl', 'flow_fin']]
        y_train = data['calss']

        # Codificar etiquetas
        label_encoder = LabelEncoder()
        y_train_encoded = label_encoder.fit_transform(y_train)

        # Entrenar árbol de decisión
        clf_tree_reduced = DecisionTreeClassifier(random_state=42)
        clf_tree_reduced.fit(X_train, y_train_encoded)

        # Graficar el árbol de decisión
        plt.figure(figsize=(12, 8))
        plot_tree(clf_tree_reduced, 
                  filled=True, 
                  feature_names=['min_flowpktl', 'flow_fin'], 
                  class_names=label_encoder.classes_.tolist(),
                  rounded=True)
        
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
        img_buffer.seek(0)
        plt.close()
        
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
        
        return jsonify({'message': 'Árbol de decisión exportado!', 'image': img_base64})

    except Exception as e:
        logger.error(f"Error en el árbol de decisión: {str(e)}")
        return jsonify({"error": str(e)}), 500

# Ejecuta la aplicación Flask
if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port)